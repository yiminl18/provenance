from openai import OpenAI
client = OpenAI()
question = "What is the name of the company receiving the notice with a non-zero civil penalty?" + " Return only one company name."
raw_answer="Tesla Power, Inc."
robustness_test_evidence_answer="Tesla Auto, Inc."

completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "user", "content": f"""You are an evaluator tasked with comparing two answers generated by ChatGPT in response to an original question. Please perform the following:
	•	Original Question: {question}
	•	Answer 1: {raw_answer}
	•	Answer 2: {robustness_test_evidence_answer}
Your Task:
	1.	Understand the Core Idea:
	•	Determine if both answers address the same idea or satisfy the requirements of the original question.
	•	If both answers fully satisfy the question and convey the same meaning, assign a score of 5.
	•	If the answers are entirely different and do not address the same idea, assign a score of 0.
Examples:
	•	If the sequence of entities isn't important and both answers contain the same entities in different orders, they can receive a score of 5.
	•	If both answers describe the same concept or satisfy the question in slightly different ways (e.g., “ICLR” and “ICLR 2024” for the question “What's the publication venue of this paper?”), they can receive a score of 5.
	2.	Partial Similarity:
	•	If some entities are the same and others are different, assign a score based on the number of matching entities.
	•	Example: If there are 5 entities in total, and 3 entities match while 2 do not, assign a score of 3.
	3.	Ignore Insignificant Differences:
	•	Disregard differences in capitalization and punctuation.
	•	Focus solely on the semantic meaning of the answers.
Output:
	•	Include a brief explanation for the assigned score based on the criteria above.
    •	Provide a similarity score between 0 and 5.
Output Format:
    •	Explanation: [Brief explanation of the score assigned]
    •   Similarity Score: **[0-5]**
"""}
    ]
)
print(completion.choices[0].message)
